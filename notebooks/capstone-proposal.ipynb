{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Proposal\n",
    "Felipe Santos\n",
    "\n",
    "October 4th, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposal\n",
    "\n",
    "My proposal to the capstone project is beating the benchmark in the Tradeshift Text Classification on Kaggle Competition, in this competition, the machine learning engineer has to classify text blocks in documents to certain labels, being a multiclass classification problem with tabular data. This competition started on 10/02/2014 and ended on 11/10/2014 and today is an featured competition.\n",
    "\n",
    "\n",
    "### Domain Background\n",
    "\"Optical character recognition (also optical character reader, OCR) is the mechanical or electronic conversion of images of typed, handwritten or printed text into machine-encoded text, whether from a scanned document, a photo of a document, a scene-photo\" [1]. This method is used as an entry method so the document became more easily stored, compact and searched. But the process only does some dummy translate from image to text so text classification algorithms come to give us information about this unstructured format and transform from document retrieval to knowledge discovery [2]. The need of automatically retrieval of useful knowledge from the huge amount of textual data in order to assist the human analysis is fully apparent [3].\n",
    "\n",
    "Tradeshift competition is about predicted the probability that a piece of text belongs to a given class. The dataset was created from thousands of documents, representing millions of words. In each document, several bounding boxes with text inside are selected and features are extracted from this texts and labels are assigned. For the text extraction process is used OCR (optical character recognition) and the supervised machine learning method is used to gain information and classify the text, the dataset is previously performed the OCR text extraction process and the features are already extracted. I want to learn about this project to gains insights into a future project of my own that have some similarities with this competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "In this competition, we have to create a supervised machine learning algorithm to predict labels from the text that is parsed from OCR and the features give to us from Tradeshift dataset. For all the documents, words are detected and combined to form text blocks that may overlap to each other. Each text block is enclosed within a spatial box, which is depicted by a red line in the sketch below. The text blocks from all documents are aggregated in a data set where each text block corresponds to one sample (row)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![text classification](imgs/text-classification.png)\n",
    "![text classification](imgs/text-classification-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Inputs\n",
    "_(approx. 2-3 paragraphs)_\n",
    "\n",
    "In this section, the dataset(s) and/or input(s) being considered for the project should be thoroughly described, such as how they relate to the problem and why they should be used. Information such as how the dataset or input is (was) obtained, and the characteristics of the dataset or input, should be included with relevant references and citations as necessary It should be clear how the dataset(s) or input(s) will be used in the project and whether their use is appropriate given the context of the problem.\n",
    "\n",
    "The files with the dataset used for this capstone is on the [link](https://www.kaggle.com/c/tradeshift-text-classification) in the section Data. We have 4 files on the link, all in the csv format with a 1-row header and each row stores a different sample and each collumn is separeted with comma:\n",
    "- **train.csv**, contains all features for the training set;\n",
    "- **trainLabels.csv**, contains one row per label per sample and the order of the rows is the align with the train.csv;\n",
    "- **test.csv**, contains all features for the testing set;\n",
    "- **sampleSubmission.csv**, contains a sample submission to the kaggle competition.\n",
    "\n",
    "This dataset has ~2.1M samples with 80% as training set and 20% as the testing set, compounding of 145 features and having 33 labels to classify. The test set is split into public (30%) and private (70%) sets, which are used for the public and the private leaderboard on the competition. The features of the dataset goes to one of these categories:\n",
    "- **Content**: The cryptographic hash of the raw text.\n",
    "- **Parsing**: Indicates if the text parses as number, text, alphanumeric, etc.\n",
    "- **Spatial**: Indicates the box position, size, etc.\n",
    "- **Relational**: Includes information about the surrounding text blocks in the original document. If there is not such a surrounding text block, e.g. a text block in the top of the document does not have any other text block upper than itself, these features are empty (no-value).\n",
    "\n",
    "The feature values can be:\n",
    "- **Numbers**. Continuous/discrete numerical values.\n",
    "- **Boolean**. The values include YES (true) or NO (false).\n",
    "- **Categorical**. Values within a finite set of possible values.\n",
    "\n",
    "Some observations: \n",
    "* The order of samples and features is random. In fact, two consecutive samples in the table will most likely not belong to the same document.\n",
    "* Some documents are OCR'ed; hence, some noise in the data is expected.\n",
    "* The documents have different formats and the text belongs to several languages.\n",
    "* The number of pages and text blocks per document is not constant.\n",
    "* The meaning of the features and class is not provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* [0] - https://www.kaggle.com/c/tradeshift-text-classification\n",
    "* [1] - https://en.wikipedia.org/wiki/Optical_character_recognition\n",
    "* [2] - http://ccis2k.org/iajit/PDF/vol.5,no.1/3-37.pdf - Zakaria Elberrichi, Abdelattif Rahmoun, and Mohamed Amine Bentaalah - Using WordNet for Text Categorization - The International Arab Journal of Information Technology, Vol. 5, No. 1, January 2008\n",
    "* [3] - http://odur.let.rug.nl/vannoord/TextCat/textcat.pdf - William B. Cavnar and John M. Trenkle - N-Gram-Based Text Categorization - Environmental Research Institute of Michigan\n",
    "* [4] - http://www.ijaiem.org/Volume2Issue3/IJAIEM-2013-03-13-025.pdf - Bhumika, Prof Sukhjit Singh Sehra, Prof Anand Nayyar - A REVIEW PAPER ON ALGORITHMS USED FOR TEXT CLASSIFICATION - International Journal of Application or Innovation in Engineering & Management (IJAIEM) - Volume 2, Issue 3, March 2013\n",
    "* [5] - https://www.researchgate.net/publication/319688772_Using_text_mining_to_classify_research_papers - Sulova, Snezhana & Todoranova, Latinka & Penchev, Bonimir & Nacheva, Radka. (2017). Using text mining to classify research papers. 10.5593/SGEM2017/21/S07.083. \n",
    "* [6] - https://www.researchgate.net/publication/280609521_Text_Classification_of_Technical_Papers_Based_on_Text_Segmentation - Nguyen, Thien & Shirai, Kiyoaki. (2013). Text Classification of Technical Papers Based on Text Segmentation. 10.1007/978-3-642-38824-8_25. \n",
    "* [7] - https://blog.tradeshift.com/hundreds-compete-to-improve-machine-learning-algorithm-for-5k-prize/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
